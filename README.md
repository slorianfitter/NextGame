# ğŸ® NextGame

> Ein Projekt zur individuellen Spieleempfehlung basierend auf der eigenen Steam-Bibliothek.

---

## ğŸ“š Inhaltsverzeichnis
1. [Warum das Projekt?](#warum-das-projekt)
2. [Was ist der Plan?](#was-ist-der-plan)
   - [1. Datenbeschaffung](#1--datenbeschaffung)
   - [2. Modell zur Vorhersage](#2--modell-zur-vorhersage)
   - [3. Frontend](#3--frontend)
3. [Aktueller Stand 10.10.2025](#-aktueller-stand-10102025)
4. [Update 16.10.2025](#-update-16102025)
5. [Update 04.11.2025](#-update-04112025)
6. [Update 19.11.2025](#-update-19112025)

---

## Warum das Projekt?

Ich spiele leidenschaftlich gerne Computerspiele und stehe regelmÃ¤ÃŸig vor dem Problem, **welches Spiel ich als NÃ¤chstes spielen mÃ¶chte**.  
Der Markt ist riesig und wÃ¤chst stetig weiter. Oft erwische ich mich dabei, wie ich endlos durch verschiedene Stores scrolle â€“ meist ohne Erfolg.

Um meine Zeit nicht mit stundenlangem Lesen von Reviews und Beschreibungen zu verschwenden, mÃ¶chte ich ein **Modell entwickeln**, das meine Spielebibliothek analysiert und mir ein Spiel vorschlÃ¤gt, das **meinen individuellen Vorlieben entspricht**.

Ich bin mir noch nicht sicher, ob das Modell nur ein einzelnes Spiel oder gleich eine **Liste mit passenden Spielen** empfehlen soll. Eine Liste wÃ¤re vermutlich sinnvoller â€“ schlieÃŸlich ist der Markt groÃŸ, und es gibt selten nur eine perfekte Option.

NatÃ¼rlich gibt es bereits Webseiten, die Spiele empfehlen. Der Unterschied: Diese Empfehlungen sind **allgemein** und nicht **personalisiert**.  
Red Dead Redemption 1 oder 2 zu empfehlen, ist keine Meisterleistung â€“ das sind Spiele, die ohnehin von fast allen gelobt werden.  
Ich mÃ¶chte dagegen ein System, das **meine persÃ¶nliche Historie** berÃ¼cksichtigt:

- Was habe ich bereits gespielt?  
- Wie lange habe ich es gespielt?  
- Welche Genres spiele ich besonders hÃ¤ufig?

Denn es bringt nichts, mir einen Simulator vorzuschlagen, wenn ich eigentlich leidenschaftlich gern Kampfspiele spiele.

---

## Was ist der Plan?

Ich teile das Projekt in **drei Hauptteile**:

---

### 1. ğŸ“Š Datenbeschaffung

GrundsÃ¤tzlich ist es schwierig, an Spieledaten zu gelangen, da Entwickler meist kein Interesse daran haben, ihre Daten zu teilen.  
**GlÃ¼cklicherweise ist Steam (Valve)** eine hervorragende Quelle: Sie erlauben Scraping und stellen **mehrere Ã¶ffentliche APIs** bereit.

FÃ¼r diese APIs braucht man teilweise einen **API-Key**, den sich jeder Steam-Nutzer einfach generieren kann.  
Daneben gibt es aber auch **API-Endpunkte ohne Key**, die Ã¶ffentlich zugÃ¤nglich sind.

Ich habe mich entschieden, mich zunÃ¤chst **vollstÃ¤ndig auf Steam-Daten** zu stÃ¼tzen, da:
- Steam die grÃ¶ÃŸte Plattform fÃ¼r den Kauf und das Spielen von PC-Spielen ist.
- Rund **270.000 Produkte** im Store gelistet sind (wovon ca. 20â€“40 % tatsÃ¤chliche Spiele sind â€“ *eigene SchÃ¤tzung, wird nach Abschluss der Datenbeschaffung verifiziert*).
- Nutzer ihre eigenen **Spielzeiten und Bibliotheken per JSON abrufen** kÃ¶nnen.
- Ã–ffentliche Profile auch **fremde Spielzeiten einsehbar** machen.

ZusÃ¤tzlich mÃ¶chte ich auch **Reviews** einbeziehen â€“ sowohl die **All-Time-Bewertungen** als auch die **Reviews der letzten 30 Tage**, um aktuelle Trends zu erkennen.

---

### 2. ğŸ§  Modell zur Vorhersage

Damit das Modell funktioniert, brauche ich verschiedene Datenpunkte â€“ insbesondere:
- Anzahl der Reviews  
- Spielzeit  
- Genres und Kategorien  

Diese Daten reichen zunÃ¤chst, um eine **Baseline** zu erstellen.  
Mein erster Ansatz ist ein **Vergleichsmodell**, da:
- das Modell simpel ist,  
- es sich gut anpassen lÃ¤sst,  
- und es gleich eine Liste von Spielen liefert, die potenziell gut passen kÃ¶nnten.

Das **Baseline-Modell** hat jedoch auch Nachteile:
- Die RÃ¼ckgabeliste kann sehr lang und ungenau werden.

Langfristig mÃ¶chte ich daher ein **komplexeres Modell** entwickeln, das bereits Ã¼ber einen gespeicherten Spielekatalog verfÃ¼gt und mit meinen Eingaben effizient arbeitet.  
Wie genau das umgesetzt wird, ist aktuell noch in Planung.

---

### 3. ğŸ’» Frontend

FÃ¼r den Nutzer soll es so einfach wie mÃ¶glich sein:  
Idealerweise kann man **per Drag & Drop oder Copy & Paste** seine Spieldaten einfÃ¼gen und bekommt anschlieÃŸend **eine schÃ¶n aufbereitete Empfehlung** mit Bild, Titel und Beschreibung.

Mein Ziel ist es, **nicht nur ein funktionales Modell**, sondern auch eine **ansprechende BenutzeroberflÃ¤che** zu entwickeln.  
Das soll mich selbst fordern und mir helfen, neue Technologien zu lernen.

Ein geplanter Zusatz ist ein **â€Ablehnenâ€œ-Button**, falls ein vorgeschlagenes Spiel nicht gewÃ¼nscht ist.  
Das ist wichtig, da viele Spieler â€“ mich eingeschlossen â€“ auf **mehreren Plattformen** spielen (z. B. PC, Xbox, PlayStation).  
Wenn ich ein Spiel also schon auf einer anderen Plattform gespielt habe, soll es **abgelehnt und durch eine neue Empfehlung ersetzt** werden.

---

## ğŸ“ Aktueller Stand 10.10.2025

Momentan befinde ich mich in der **Datenbeschaffungsphase**.  
Die Skripte sind geschrieben und laufen bereits seit rund zwei Tagen kontinuierlich.

### Aktuelles Problem

Steam reagiert nicht besonders begeistert, wenn ich **gleichzeitig API-Anfragen** stelle und **den Store nach Reviews abfrage** â€“ das fÃ¼hrte bisher zu **mehrstÃ¼ndigen Timeouts**.

Deshalb beschaffe ich die Daten nun **sequenziell**, also nacheinander.  

Der aktuelle Ablauf:
1. Spiele werden von Nicht-Spielen (z. B. DLCs, Add-ons) gefiltert.  
2. Pro Spiel-ID werden Daten abgefragt.  

Das Ganze dauert etwa **vier Tage**, da:
- Steam bei API-Keys **100.000 Anfragen pro Tag** erlaubt.  
- Ich derzeit eine API **ohne Key** nutze, die anscheinend andere Limits hat.  

Nach meinen Tests liegt der **Sweet Spot** bei etwa **40 Anfragen pro Minute** â€“ das ergibt ca. **57.000 Anfragen pro Tag**,  
was wiederum rund **4,5 Tage** fÃ¼r alle 270.000 IDs bedeutet.  
Danach mÃ¼ssen noch die restlichen Spieldaten ergÃ¤nzt werden, was ebenfalls mehrere Tage in Anspruch nehmen wird.

---

## ğŸ“† Update 16.10.2025

Die ganzen AppIDs sind nun alle abgeklappert und ich habe etwas mehr als 100 Tausend Spiele identifizieren kÃ¶nnen. 

Bei der Datenaufbereitung sind mir allerdings viele Probleme aufgefallen:
- rund 100 Tausend Zeilen NAs -> bedeutet, mein Skript war nicht sehr sicher und hat deutliche LÃ¼cken.  
- Weil das Skript solche LÃ¼cken hat, muss ich das Ganze jetzt nochmal machen.  
- Steam ist leider nicht so einheitlich, wie ich es gerne hÃ¤tte.

Das Ganze ist mir nÃ¤mlich aufgefallen durch die NAs bei der AltersbeschrÃ¤nkung. Neben den klassischen Werten wie 0, 6, 12 usw. kamen auch Strings und die positive Grenze von Int64 heraus.  
Damit ein Spiel in Deutschland sichtbar ist, muss es eine AltersbeschrÃ¤nkung geben. Entweder von USK oder von Steam selbst.  
Mein Code war diesbezÃ¼glich nicht robust. Ich habe nur gecheckt, ob ein Item im JSON enthalten ist, nicht, ob es leer ist â€“ mein Fehler.

Ein Fehler, der jetzt leider schmerzt, weil ich dick hinter meinem eigenen Zeitplan liege.

---

### ğŸ›« Plan fÃ¼r die kommenden Tage

- Code nochmal anpassen, robuster und effektiver  
- Die fehlenden Daten nochmals beschaffen  
- Daten aufbereiten  

Sobald diese drei Unterpunkte erledigt sind, werde ich nochmals ein Update schicken und das weitere Vorgehen niederschreiben.

Das Ganze ist sehr Ã¤rgerlich, aber nicht schlimm, weil ich aus Fehlern lerne und nun weiÃŸ, dass ich in Zukunft robuster programmieren muss.

---

## ğŸ“† Update 04.11.2025

Ich habe begonnen, ein **Interface mit Streamlit** zu entwickeln, um die Nutzerdaten Ã¼bersichtlich darzustellen.  
Das grundlegende **Streamlit-Interface steht bereits**, benÃ¶tigt aber noch **Feinschliff im Design**.  
Ebenso muss das Skript spÃ¤ter angepasst werden, sobald alle Modelle stehen und weitere Daten vorliegen.


---

### ğŸ’­ Aktuelle Gedanken

Ich plane aktuell, **drei Modelle** zu implementieren:

#### ğŸ”¹ Modell 1 â€“ Basismodell
Ein einfaches Modell, das eine Liste von Spielen aus dem **meistgespielten Genre** vorschlÃ¤gt.

#### ğŸ”¹ Modell 2 â€“ Distanzmodell
Ein Modell, das **AbstÃ¤nde zwischen Spielen** misst.  
Ich bin mir noch nicht sicher, ob ich dafÃ¼r einen **k-NN-Algorithmus** oder **K-Means** verwenden werde.  
Ziel ist es, **Ã¤hnliche Spiele zu identifizieren**, basierend auf:
- Genre  
- Kategorien  
- User-Tags  

#### ğŸ”¹ Modell 3 â€“ Erweiterung von Modell 2
Dieses Modell soll zusÃ¤tzlich auch **Reviews** mit einbeziehen.  
Reviews sind zwar subjektiv, aber bei einer groÃŸen Menge lÃ¤sst sich ein **klarer Trend** erkennen.  
Das Ziel ist eine **realistische, personalisierte Prognose**, die den Nutzer optimal zufriedensellt.

---

### âœ… Fertige Gedanken

Das erste Modell ist bereits **fertiggestellt**.  
Es handelt sich um ein **Basismodell**, das das meistgespielte Genre auswÃ¤hlt und eine **Liste von 10 zufÃ¤lligen Spielen** dieses Genres vorschlÃ¤gt.

**Folgen:**
- Das Modell ist **nicht prÃ¤zise**,  
- bietet aber dafÃ¼r **viel Abwechslung** in den VorschlÃ¤gen.

Beispielsweise wÃ¤hlt es beim Genre *Action* aus rund **35.000 Spielen** aus.

---

### ğŸ Weitere Fortschritte

Neben dem Modell habe ich einen **HTML-Scraper** geschrieben, der mir:
- **Reviews**,  
- **Tags**  
- und **Preise**  

automatisch beschafft.

Die **Preise** dienen als Kontrolle, falls im JSON der Steam-API fehlerhafte Werte stehen.  
**Reviews** und **Tags** werden fÃ¼r Modell 2 und 3 benÃ¶tigt.

Da jede **Shopseite einzeln aufgerufen** werden muss, dauert das Sammeln der Daten entsprechend lange:  
- Aktuell hole ich **ein Request alle zwei Sekunden**.

Ein Ã¤rgerlicher Fehler war, dass ich **anfangs die Tags nicht mitgescraped** habe.  
Dadurch musste ich die vorherige Beschaffung abbrechen und **von vorne beginnen** â€“ ein klassischer, aber lehrreicher RÃ¼ckschlag.

---

### ğŸ›« Plan fÃ¼r die kommenden Tage (Part 2)

- Das **Distanzmodell** schreiben und erste Tests durchfÃ¼hren  
- Eventuell das **Distanzmodell direkt im Streamlit-Interface** implementieren  
- Parallel weiterhin Daten beschaffen (**Tags**, **Reviews**, **Preise**)  
- **Design-Feinschliff** im Streamlit-Frontend 

---

## ğŸ“† Update 19.11.2025

Das Projekt ist so gut wie abgeschlossen.  
Alle bislang notwendigen Daten sind bereits seit einer Woche vollstÃ¤ndig erhoben und bearbeitet. Es benÃ¶tigt nur noch einen Feinschliff der Labels und Korrektur kleinerer Tippfehler.

### ğŸ”¹ Modell 1
Modell 1 steht seit Wochen und funktioniert wie geplant.  

### ğŸ”¹ Modell 2
Modell 2 wurde vorgestern fertiggestellt und hat einige Schwierigkeiten verursacht.  
Der Grundansatz war ein einfaches DistanzmaÃŸ zwischen Spielen. Ein sehr naiver Ansatz, der theoretisch funktioniert, hier aber aufgrund der BinÃ¤rdaten nicht optimal war.  

Das Distanzmodell berÃ¼cksichtigt nicht nur die euklidische Distanz zwischen den Spielemerkmalen, sondern filtert vorher auch den Winkel der Vektoren. Dadurch kÃ¶nnen Ã¤hnliche Spiele zum aktuellen Nutzerprofil identifiziert werden.  

ZusÃ¤tzlich habe ich es dem Nutzer ermÃ¶glicht, sein Profil einzusehen und bei Bedarf zu bearbeiten. Die genauen Instruktionen fÃ¼r das Profil mÃ¼ssen allerdings noch in das Interface implementiert werden.  

Insgesamt liefert das Modell jedoch solide Ergebnisse, und ich bin vorerst zufrieden.

### ğŸ”¹ Modell 3
Modell 3 befindet sich noch in der Entwicklung. Ziel ist, die **Reviews** zusÃ¤tzlich zu berÃ¼cksichtigen. Dabei habe ich bisher einige Herausforderungen festgestellt:

- 75â€¯% aller Spiele haben weniger als 130 Reviews. Das bedeutet nicht, dass sie schlechte Spiele sind.  
- Klassische AnsÃ¤tze wie:
  - positive Reviews / Gesamtanzahl der Reviews â†’ starke Verzerrung bei Spielen mit wenigen Reviews  
  - positive Reviews âˆ’ negative Reviews â†’ ermÃ¶glicht, dass kleine Spiele negativ dominieren
    
  fÃ¼hren zu Problemen.

**LÃ¶sungsansÃ¤tze**, die ich nun testen mÃ¶chte:

- Wilson Lower Bound  
- Bayesian Weighted Rating  
- Wald-Intervall  
- Agresti-Coull-Intervall  

Ziel ist es, die Methode zu finden, die am sinnvollsten Ergebnisse liefert.  
AuÃŸerdem wird weiterhin nach anderen Methoden Ausschau gehalten.


### ğŸ›« NÃ¤chste Schritte
- Implementierung der GrundzÃ¼ge von Model 3  
- Testen verschiedener Methoden zur Berechnung von Bewertungen basierend auf Reviews  
- Feinschliff im Interface, insbesondere fÃ¼r die Profilbearbeitung

 
- Mit den **GrundzÃ¼gen des dritten Modells** beginnen



